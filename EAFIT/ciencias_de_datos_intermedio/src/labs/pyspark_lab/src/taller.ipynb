{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller Pyspark - Ciencia de datos Intermedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escoger un dataset (que tenga tanto variables numericas como categoricas)\n",
    "  - Dataset seleccionado **adult.csv** de la carpeta del curso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el dataset y convertirlo a archivo parquet, Json, CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult = pd.read_csv('adult.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult.to_json('adult.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult.to_parquet('adult.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar con los diferentes formatos con Pyspark, utilizar las dos formas de caragr un dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/23 19:24:07 WARN Utils: Your hostname, FACTORED-Q69X24VHF3.local resolves to a loopback address: 127.0.0.1; using 192.168.0.2 instead (on interface en0)\n",
      "22/11/23 19:24:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/23 19:24:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, FloatType, IntegerType\n",
    "from pyspark.sql.functions import * #  countDistinct, col, desc, asc, isnan, when, count, avg, min, max\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "import pyspark.sql.functions as F\n",
    "spark = SparkSession.builder.appName(\"PySparkSession\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formas de leer CSV en Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+---------+-------------+------------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "|age|       workclass|fnlwgt|education|education-num|    marital-status|     occupation| relationship| race| sex|capitalgain|capitalloss|hoursperweek|native-country|class|\n",
      "+---+----------------+------+---------+-------------+------------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "|  2|       State-gov| 77516|Bachelors|           13|     Never-married|   Adm-clerical|Not-in-family|White|Male|          1|          0|           2| United-States|<=50K|\n",
      "|  3|Self-emp-not-inc| 83311|Bachelors|           13|Married-civ-spouse|Exec-managerial|      Husband|White|Male|          0|          0|           0| United-States|<=50K|\n",
      "+---+----------------+------+---------+-------------+------------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_format = spark.read.format(\"csv\")\\\n",
    "                                .option(\"header\", \"true\")\\\n",
    "                                .option(\"nullValue\", \"?\")\\\n",
    "                                .option(\"encoding\", \"utf8\")\\\n",
    "                                .load(\"./adult.csv\")\n",
    "df_spark_format.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+---------+-------------+------------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "|age|       workclass|fnlwgt|education|education-num|    marital-status|     occupation| relationship| race| sex|capitalgain|capitalloss|hoursperweek|native-country|class|\n",
      "+---+----------------+------+---------+-------------+------------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "|  2|       State-gov| 77516|Bachelors|           13|     Never-married|   Adm-clerical|Not-in-family|White|Male|          1|          0|           2| United-States|<=50K|\n",
      "|  3|Self-emp-not-inc| 83311|Bachelors|           13|Married-civ-spouse|Exec-managerial|      Husband|White|Male|          0|          0|           0| United-States|<=50K|\n",
      "+---+----------------+------+---------+-------------+------------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.csv(\"./adult.csv\",\n",
    "                            header = True,\n",
    "                            sep = \",\",\n",
    "                            nullValue = \"?\",\n",
    "                            encoding = \"utf8\")\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formas de leer parquet con Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+---------+-------------+------------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "|age|       workclass|fnlwgt|education|education-num|    marital-status|     occupation| relationship| race| sex|capitalgain|capitalloss|hoursperweek|native-country|class|\n",
      "+---+----------------+------+---------+-------------+------------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "|  2|       State-gov| 77516|Bachelors|           13|     Never-married|   Adm-clerical|Not-in-family|White|Male|          1|          0|           2| United-States|<=50K|\n",
      "|  3|Self-emp-not-inc| 83311|Bachelors|           13|Married-civ-spouse|Exec-managerial|      Husband|White|Male|          0|          0|           0| United-States|<=50K|\n",
      "+---+----------------+------+---------+-------------+------------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.parquet(\"./adult.parquet\",\n",
    "                            header = True,\n",
    "                            sep = \",\",\n",
    "                            nullValue = \"?\",\n",
    "                            encoding = \"utf8\")\n",
    "\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+---------+-------------+------------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "|age|       workclass|fnlwgt|education|education-num|    marital-status|     occupation| relationship| race| sex|capitalgain|capitalloss|hoursperweek|native-country|class|\n",
      "+---+----------------+------+---------+-------------+------------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "|  2|       State-gov| 77516|Bachelors|           13|     Never-married|   Adm-clerical|Not-in-family|White|Male|          1|          0|           2| United-States|<=50K|\n",
      "|  3|Self-emp-not-inc| 83311|Bachelors|           13|Married-civ-spouse|Exec-managerial|      Husband|White|Male|          0|          0|           0| United-States|<=50K|\n",
      "+---+----------------+------+---------+-------------+------------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.format(\"parquet\")\\\n",
    "                        .option(\"header\", \"true\")\\\n",
    "                        .option(\"nullValue\", \"?\")\\\n",
    "                        .option(\"encoding\", \"utf8\")\\\n",
    "                        .load(\"./adult.parquet\")\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formas de leer un Json con Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-----------+-----+---------+-------------+------+------------+------------------+--------------+---------------+-----+-------------+----+----------------+\n",
      "|age|capitalgain|capitalloss|class|education|education-num|fnlwgt|hoursperweek|    marital-status|native-country|     occupation| race| relationship| sex|       workclass|\n",
      "+---+-----------+-----------+-----+---------+-------------+------+------------+------------------+--------------+---------------+-----+-------------+----+----------------+\n",
      "|  2|          1|          0|<=50K|Bachelors|           13| 77516|           2|     Never-married| United-States|   Adm-clerical|White|Not-in-family|Male|       State-gov|\n",
      "|  3|          0|          0|<=50K|Bachelors|           13| 83311|           0|Married-civ-spouse| United-States|Exec-managerial|White|      Husband|Male|Self-emp-not-inc|\n",
      "+---+-----------+-----------+-----+---------+-------------+------+------------+------------------+--------------+---------------+-----+-------------+----+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.format(\"json\")\\\n",
    "                        .option(\"encoding\",\"utf8\")\\\n",
    "                        .load(\"./adult.json\")\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-----------+-----+---------+-------------+------+------------+------------------+--------------+---------------+-----+-------------+----+----------------+\n",
      "|age|capitalgain|capitalloss|class|education|education-num|fnlwgt|hoursperweek|    marital-status|native-country|     occupation| race| relationship| sex|       workclass|\n",
      "+---+-----------+-----------+-----+---------+-------------+------+------------+------------------+--------------+---------------+-----+-------------+----+----------------+\n",
      "|  2|          1|          0|<=50K|Bachelors|           13| 77516|           2|     Never-married| United-States|   Adm-clerical|White|Not-in-family|Male|       State-gov|\n",
      "|  3|          0|          0|<=50K|Bachelors|           13| 83311|           0|Married-civ-spouse| United-States|Exec-managerial|White|      Husband|Male|Self-emp-not-inc|\n",
      "+---+-----------+-----------+-----+---------+-------------+------+------------+------------------+--------------+---------------+-----+-------------+----+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.json(\"./adult.json\",\n",
    "                               encoding = \"utf8\")\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir el schema de todas las columnas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_schemas = {\n",
    "            \"age\": (LongType(), False),\n",
    "            \"workclass\": (StringType(), True),\n",
    "            \"fnlwgt\": (LongType(), False),\n",
    "            \"education\": (StringType(), False),\n",
    "            \"education_num\": (LongType(), False),\n",
    "            \"marital_status\": (StringType(), False),\n",
    "            \"occupation\": (StringType(), True),\n",
    "            \"relationship\": (StringType(), False),\n",
    "            \"race\": (StringType(), False),\n",
    "            \"sex\": (StringType(), False),\n",
    "            \"capitalgain\": (LongType(), False),\n",
    "            \"capitalloss\": (LongType(), False),\n",
    "            \"hoursperweek\": (LongType(), False),\n",
    "            \"native_country\": (StringType(), True),\n",
    "            \"class\": (StringType(), False)\n",
    "        }\n",
    "\n",
    "def schema(cols_schema: dict) -> StructType:\n",
    "    \"\"\"Define the schema of the dataframe\n",
    "\n",
    "    Args:\n",
    "        cols_schema (dict): Dictionary with the columns and its types\n",
    "\n",
    "    Returns:\n",
    "        StructType: Schema of the dataframe\n",
    "    \"\"\"\n",
    "    return StructType([StructField(key,\n",
    "                                cols_schemas[key][0],\n",
    "                                cols_schemas[key][1]) for key in cols_schemas.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df = schema(cols_schemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forma 1 para usar el schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+---------+-------------+--------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "|age|       workclass|fnlwgt|education|education_num|marital_status|     occupation| relationship| race| sex|capitalgain|capitalloss|hoursperweek|native_country|class|\n",
      "+---+----------------+------+---------+-------------+--------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "|  2|       State-gov| 77516|Bachelors|         null|          null|   Adm-clerical|Not-in-family|White|Male|          1|          0|           2|          null|<=50K|\n",
      "|  3|Self-emp-not-inc| 83311|Bachelors|         null|          null|Exec-managerial|      Husband|White|Male|          0|          0|           0|          null|<=50K|\n",
      "+---+----------------+------+---------+-------------+--------------+---------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_format = spark.read.format(\"parquet\")\\\n",
    "                                .option(\"header\", \"true\")\\\n",
    "                                .option(\"nullValue\", \"?\")\\\n",
    "                                .option(\"encoding\", \"utf8\")\\\n",
    "                                .schema(schema_df)\\\n",
    "                                .load(\"./adult.parquet\")\n",
    "df_spark_format.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forma 2 para usar el schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------+---------+-------------+--------------+------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "| age|workclass|fnlwgt|education|education_num|marital_status|  occupation| relationship| race| sex|capitalgain|capitalloss|hoursperweek|native_country|class|\n",
      "+----+---------+------+---------+-------------+--------------+------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "|null|workclass|  null|education|         null|marital-status|  occupation| relationship| race| sex|       null|       null|        null|native-country|class|\n",
      "|   2|State-gov| 77516|Bachelors|           13| Never-married|Adm-clerical|Not-in-family|White|Male|          1|          0|           2| United-States|<=50K|\n",
      "+----+---------+------+---------+-------------+--------------+------------+-------------+-----+----+-----------+-----------+------------+--------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.csv(\"./adult.csv\",schema=schema_df,)\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular medidas de tendencia central (media, mediana y moda) con Pyspark y SparkSQL mínimo para la mitad de las variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------------+-----------+-----------+------------+\n",
      "| age|fnlwgt|education_num|capitalgain|capitalloss|hoursperweek|\n",
      "+----+------+-------------+-----------+-----------+------------+\n",
      "|null|  null|         null|       null|       null|        null|\n",
      "|   2| 77516|           13|          1|          0|           2|\n",
      "|   3| 83311|           13|          0|          0|           0|\n",
      "+----+------+-------------+-----------+-----------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter the numerical variable in the dataframe\n",
    "numericas = [c for c,t in df_spark.dtypes if t in ['bigint']]\n",
    "df_num = df_spark.select(numericas)\n",
    "df_num.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_pyspark(df_spark: DataFrame) -> dict:\n",
    "        return {\n",
    "            'avg_' + col: df_spark.select(\n",
    "                avg(col).alias('avg_'+col)\n",
    "            ).collect()[0][0]\n",
    "            for col in cols_schemas.keys()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'avg_age': 1.7710781704270915,\n",
       " 'avg_workclass': None,\n",
       " 'avg_fnlwgt': 189664.13459727284,\n",
       " 'avg_education': None,\n",
       " 'avg_education_num': 10.078088530363212,\n",
       " 'avg_marital_status': None,\n",
       " 'avg_occupation': None,\n",
       " 'avg_relationship': None,\n",
       " 'avg_race': None,\n",
       " 'avg_sex': None,\n",
       " 'avg_capitalgain': 0.20031939724008027,\n",
       " 'avg_capitalloss': 0.1149420580647803,\n",
       " 'avg_hoursperweek': 1.9506981696081243,\n",
       " 'avg_native_country': None,\n",
       " 'avg_class': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media = get_mean_pyspark(df_spark)\n",
    "media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moda_pyspark(df_spark):\n",
    "    dic_moda = {}\n",
    "    list_dic = []\n",
    "    for item,_ in df_spark.dtypes:\n",
    "        key , value = item+'_Moda', df_spark.filter(col(item).isNotNull()).groupBy(item)\\\n",
    "                                                            .count()\\\n",
    "                                                            .orderBy(\"count\", ascending=False)\\\n",
    "                                                            .collect()[0]\\\n",
    "                                                            .__getitem__(item)\n",
    "        dic_moda[key] = value\n",
    "\n",
    "    list_dic.append(dic_moda)\n",
    "    return list_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age_Moda': 1,\n",
       "  'workclass_Moda': 'Private',\n",
       "  'fnlwgt_Moda': 203488,\n",
       "  'education_Moda': 'HS-grad',\n",
       "  'education_num_Moda': 9,\n",
       "  'marital_status_Moda': 'Married-civ-spouse',\n",
       "  'occupation_Moda': 'Prof-specialty',\n",
       "  'relationship_Moda': 'Husband',\n",
       "  'race_Moda': 'White',\n",
       "  'sex_Moda': 'Male',\n",
       "  'capitalgain_Moda': 0,\n",
       "  'capitalloss_Moda': 0,\n",
       "  'hoursperweek_Moda': 2,\n",
       "  'native_country_Moda': 'United-States',\n",
       "  'class_Moda': '<=50K'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moda = get_moda_pyspark(df_spark)\n",
    "moda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_pyspark(df_spark: DataFrame) -> dict:\n",
    "    return {\n",
    "        'median_' + col: df_spark.select(\n",
    "            percentile_approx(col, 0.5).alias('median_'+col)\n",
    "        ).collect()[0][0]\n",
    "        for col in cols_schemas.keys()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'median_age': 2,\n",
       " 'median_workclass': None,\n",
       " 'median_fnlwgt': 178134,\n",
       " 'median_education': None,\n",
       " 'median_education_num': 10,\n",
       " 'median_marital_status': None,\n",
       " 'median_occupation': None,\n",
       " 'median_relationship': None,\n",
       " 'median_race': None,\n",
       " 'median_sex': None,\n",
       " 'median_capitalgain': 0,\n",
       " 'median_capitalloss': 0,\n",
       " 'median_hoursperweek': 2,\n",
       " 'median_native_country': None,\n",
       " 'median_class': None}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediana = get_median_pyspark(df_spark)\n",
    "mediana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.createOrReplaceTempView(\"df_spark_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_num_variables_string = \", \".join([f'AVG({col}) as AVG_{col}' for col,_ in df_spark.dtypes if _ in ['bigint']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|           AVG_age|        AVG_fnlwgt| AVG_education_num|    AVG_capitalgain|   AVG_capitalloss|  AVG_hoursperweek|\n",
      "+------------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|1.7710781704270915|189664.13459727284|10.078088530363212|0.20031939724008027|0.1149420580647803|1.9506981696081243|\n",
      "+------------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the average of the numerical variables\n",
    "spark.sql(f\"\"\"SELECT\n",
    "        {avg_num_variables_string}\n",
    "        FROM df_spark_view\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 228:=========================================================(2 + 0) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----------+--------------+------------------+-------------------+---------------+-----------------+---------+--------+----------------+----------------+-----------------+-------------------+----------+\n",
      "|age_Moda|workclass_Moda|fnlwgt_Moda|education_Moda|education_num_Moda|marital_status_Moda|occupation_Moda|relationship_Moda|race_Moda|sex_Moda|capitalgain_Moda|capitalloss_Moda|hoursperweek_Moda|native_country_Moda|class_Moda|\n",
      "+--------+--------------+-----------+--------------+------------------+-------------------+---------------+-----------------+---------+--------+----------------+----------------+-----------------+-------------------+----------+\n",
      "|       4|     workclass|    1490400|     education|                16|     marital-status|     occupation|     relationship|     race|     sex|               4|               4|                4|     native-country|     class|\n",
      "+--------+--------------+-----------+--------------+------------------+-------------------+---------------+-----------------+---------+--------+----------------+----------------+-----------------+-------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# get the mode of the categorical variables\n",
    "spark.sql(f\"\"\"SELECT\n",
    "        {', '.join([f'MAX({i}) as {i}_Moda' for i,_ in df_spark.dtypes])}\n",
    "        FROM df_spark_view\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediana_num_variables_string = ', '.join([f\"PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY {col}) OVER() AS mediana_{col}\" for col,_ in df_spark.dtypes if _ in ['bigint']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/23 19:25:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/11/23 19:25:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/11/23 19:25:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/11/23 19:25:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 233:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+---------------------+-------------------+-------------------+--------------------+\n",
      "|mediana_age|mediana_fnlwgt|mediana_education_num|mediana_capitalgain|mediana_capitalloss|mediana_hoursperweek|\n",
      "+-----------+--------------+---------------------+-------------------+-------------------+--------------------+\n",
      "|        2.0|      178144.5|                 10.0|                0.0|                0.0|                 2.0|\n",
      "+-----------+--------------+---------------------+-------------------+-------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# get the median of the numerical variables\n",
    "spark.sql(f\"\"\"SELECT\n",
    "        {mediana_num_variables_string}\n",
    "        FROM df_spark_view\n",
    "        LIMIT 1\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular medidas de dispersion (varianza, desviacion estandar y Coeficiente de variacion), consultar como hacerlo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desviación estandar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the dispersion measures of the numerical variables\n",
    "def get_stddev_pyspark(df_spark: DataFrame) -> dict:\n",
    "    return {\n",
    "        'std_' + col: df_spark.select(\n",
    "            stddev(col).alias('std_'+col)\n",
    "        ).collect()[0][0]\n",
    "        for col in cols_schemas.keys()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'std_age': 1.6780046482165683,\n",
       " 'std_workclass': None,\n",
       " 'std_fnlwgt': 11152210185.574898,\n",
       " 'std_education': None,\n",
       " 'std_education_num': 6.609900909997683,\n",
       " 'std_marital_status': None,\n",
       " 'std_occupation': None,\n",
       " 'std_relationship': None,\n",
       " 'std_race': None,\n",
       " 'std_sex': None,\n",
       " 'std_capitalgain': 0.556787842538093,\n",
       " 'std_capitalloss': 0.31016390503929436,\n",
       " 'std_hoursperweek': 0.804678061309482,\n",
       " 'std_native_country': None,\n",
       " 'std_class': None}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stddev_pyspark(df_spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variance_pyspark(df_spark: DataFrame) -> dict:\n",
    "    return {\n",
    "        'std_' + col: df_spark.select(\n",
    "            variance(col).alias('std_'+col)\n",
    "        ).collect()[0][0]\n",
    "        for col in cols_schemas.keys()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'std_age': 1.6780046482165683,\n",
       " 'std_workclass': None,\n",
       " 'std_fnlwgt': 11152210185.574898,\n",
       " 'std_education': None,\n",
       " 'std_education_num': 6.609900909997683,\n",
       " 'std_marital_status': None,\n",
       " 'std_occupation': None,\n",
       " 'std_relationship': None,\n",
       " 'std_race': None,\n",
       " 'std_sex': None,\n",
       " 'std_capitalgain': 0.556787842538093,\n",
       " 'std_capitalloss': 0.31016390503929436,\n",
       " 'std_hoursperweek': 0.804678061309482,\n",
       " 'std_native_country': None,\n",
       " 'std_class': None}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_variance_pyspark(df_spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coeficiente de variación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coef_var_pyspark(df_spark: DataFrame) -> dict:\n",
    "    variables_numericas = [c for c,t in df_spark.dtypes if t in ['bigint']]\n",
    "    cv = [(F.stddev(col)/F.avg(col)).alias('cv_' + col) for col in variables_numericas]\n",
    "    results = df_spark.select(cv).first()\n",
    "    coef_var_dict = dict()\n",
    "\n",
    "    for col in numericas:\n",
    "        cvi= results['cv_'+ col]\n",
    "        coef_var_dict[col] = cvi\n",
    "    return coef_var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 0.7314065572949952,\n",
       " 'fnlwgt': 0.5567949135317225,\n",
       " 'education_num': 0.2551051965704063,\n",
       " 'capitalgain': 3.7249621760481983,\n",
       " 'capitalloss': 4.845255229280509,\n",
       " 'hoursperweek': 0.45985509642806494}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coef_var_pyspark(df_spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizar mínimo 5 groupbys con Pyspark y con SparkSQL crear una tabla temporar para realizar lo mismo, y mínimo uno con pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "| age|sum(education_num)|\n",
      "+----+------------------+\n",
      "|   0|             90671|\n",
      "|null|              null|\n",
      "|   1|            130492|\n",
      "|   3|             85269|\n",
      "|   2|            126026|\n",
      "|   4|             59776|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.groupBy('age').sum('education_num').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1440:============================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-----------------+\n",
      "| age|education_num|sum(hoursperweek)|\n",
      "+----+-------------+-----------------+\n",
      "|   0|           13|             1765|\n",
      "|   3|            5|              250|\n",
      "|   2|           15|              769|\n",
      "|   2|            6|              416|\n",
      "|   1|            3|              201|\n",
      "|   3|           14|             1710|\n",
      "|   4|            7|              314|\n",
      "|   0|           11|              440|\n",
      "|   2|            5|              270|\n",
      "|   3|           13|             2980|\n",
      "|   2|           14|             2068|\n",
      "|   2|            9|             7907|\n",
      "|   3|           16|              472|\n",
      "|   1|            1|               26|\n",
      "|   0|           10|             4226|\n",
      "|   0|            9|             4837|\n",
      "|   3|           15|              482|\n",
      "|   3|            4|              420|\n",
      "|null|         null|             null|\n",
      "|   4|           10|             1690|\n",
      "+----+-------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_spark.groupBy('age','education_num').sum('hoursperweek').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "| age|sum(education_num)|\n",
      "+----+------------------+\n",
      "|   0|             90671|\n",
      "|null|              null|\n",
      "|   1|            130492|\n",
      "|   3|             85269|\n",
      "|   2|            126026|\n",
      "|   4|             59776|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT  age, sum(education_num)\n",
    "    FROM df_spark_view\n",
    "    GROUP BY age\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1449:>                                                       (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-----------------+\n",
      "| age|education_num|sum(hoursperweek)|\n",
      "+----+-------------+-----------------+\n",
      "|   0|           13|             1765|\n",
      "|   3|            5|              250|\n",
      "|   2|           15|              769|\n",
      "|   2|            6|              416|\n",
      "|   1|            3|              201|\n",
      "|   3|           14|             1710|\n",
      "|   4|            7|              314|\n",
      "|   0|           11|              440|\n",
      "|   2|            5|              270|\n",
      "|   3|           13|             2980|\n",
      "|   2|           14|             2068|\n",
      "|   2|            9|             7907|\n",
      "|   3|           16|              472|\n",
      "|   1|            1|               26|\n",
      "|   0|           10|             4226|\n",
      "|   0|            9|             4837|\n",
      "|   3|           15|              482|\n",
      "|   3|            4|              420|\n",
      "|null|         null|             null|\n",
      "|   4|           10|             1690|\n",
      "+----+-------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT  age, education_num, sum(hoursperweek)\n",
    "    FROM df_spark_view\n",
    "    GROUP BY age, education_num\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education-num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     education-num\n",
       "age               \n",
       "0            90671\n",
       "1           130492\n",
       "2           126026\n",
       "3            85269\n",
       "4            59776"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult.groupby(['age']).agg({'education-num':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>hoursperweek</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th>12</th>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   hoursperweek\n",
       "age education-num              \n",
       "0   1                        28\n",
       "    2                        48\n",
       "    3                       136\n",
       "    4                       163\n",
       "    5                       237\n",
       "...                         ...\n",
       "4   12                      183\n",
       "    13                     1452\n",
       "    14                      733\n",
       "    15                      285\n",
       "    16                      280\n",
       "\n",
       "[80 rows x 1 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult.groupby(['age','education-num']).agg({'hoursperweek':'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscar un dataset que incluya diferentes tablas, y con pyspark realizar un inner join, left join y right join, realizarlo tambien con SparkSQL y con Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## realizar distinct count de cada columna categorica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital_status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'native_country',\n",
       " 'class']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricas = [c for c,t in df_spark.dtypes if t in ['string']]\n",
    "categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+-----+\n",
      "|       workclass|Cantidad|Share|\n",
      "+----------------+--------+-----+\n",
      "|         Private|   33906|69.42|\n",
      "|Self-emp-not-inc|    3862| 7.91|\n",
      "|       Local-gov|    3136| 6.42|\n",
      "|       State-gov|    1981| 4.06|\n",
      "|    Self-emp-inc|    1695| 3.47|\n",
      "|     Federal-gov|    1432| 2.93|\n",
      "|     Without-pay|      21| 0.04|\n",
      "|    Never-worked|      10| 0.02|\n",
      "|       workclass|       1|  0.0|\n",
      "|            null|       0|  0.0|\n",
      "+----------------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+\n",
      "|   education|Cantidad|Share|\n",
      "+------------+--------+-----+\n",
      "|     HS-grad|   15784|32.32|\n",
      "|Some-college|   10878|22.27|\n",
      "|   Bachelors|    8025|16.43|\n",
      "|     Masters|    2657| 5.44|\n",
      "|   Assoc-voc|    2061| 4.22|\n",
      "|        11th|    1812| 3.71|\n",
      "|  Assoc-acdm|    1601| 3.28|\n",
      "|        10th|    1389| 2.84|\n",
      "|     7th-8th|     955| 1.96|\n",
      "| Prof-school|     834| 1.71|\n",
      "|         9th|     756| 1.55|\n",
      "|        12th|     657| 1.35|\n",
      "|   Doctorate|     594| 1.22|\n",
      "|     5th-6th|     509| 1.04|\n",
      "|     1st-4th|     247| 0.51|\n",
      "|   Preschool|      83| 0.17|\n",
      "|   education|       1|  0.0|\n",
      "+------------+--------+-----+\n",
      "\n",
      "+--------------------+--------+-----+\n",
      "|      marital_status|Cantidad|Share|\n",
      "+--------------------+--------+-----+\n",
      "|  Married-civ-spouse|   22379|45.82|\n",
      "|       Never-married|   16117| 33.0|\n",
      "|            Divorced|    6633|13.58|\n",
      "|           Separated|    1530| 3.13|\n",
      "|             Widowed|    1518| 3.11|\n",
      "|Married-spouse-ab...|     628| 1.29|\n",
      "|   Married-AF-spouse|      37| 0.08|\n",
      "|      marital-status|       1|  0.0|\n",
      "+--------------------+--------+-----+\n",
      "\n",
      "+-----------------+--------+-----+\n",
      "|       occupation|Cantidad|Share|\n",
      "+-----------------+--------+-----+\n",
      "|   Prof-specialty|    6172|12.64|\n",
      "|     Craft-repair|    6112|12.51|\n",
      "|  Exec-managerial|    6086|12.46|\n",
      "|     Adm-clerical|    5611|11.49|\n",
      "|            Sales|    5504|11.27|\n",
      "|    Other-service|    4923|10.08|\n",
      "|Machine-op-inspct|    3022| 6.19|\n",
      "| Transport-moving|    2355| 4.82|\n",
      "|Handlers-cleaners|    2072| 4.24|\n",
      "|  Farming-fishing|    1490| 3.05|\n",
      "|     Tech-support|    1446| 2.96|\n",
      "|  Protective-serv|     983| 2.01|\n",
      "|  Priv-house-serv|     242|  0.5|\n",
      "|     Armed-Forces|      15| 0.03|\n",
      "|       occupation|       1|  0.0|\n",
      "|             null|       0|  0.0|\n",
      "+-----------------+--------+-----+\n",
      "\n",
      "+--------------+--------+-----+\n",
      "|  relationship|Cantidad|Share|\n",
      "+--------------+--------+-----+\n",
      "|       Husband|   19716|40.37|\n",
      "| Not-in-family|   12583|25.76|\n",
      "|     Own-child|    7581|15.52|\n",
      "|     Unmarried|    5125|10.49|\n",
      "|          Wife|    2331| 4.77|\n",
      "|Other-relative|    1506| 3.08|\n",
      "|  relationship|       1|  0.0|\n",
      "+--------------+--------+-----+\n",
      "\n",
      "+------------------+--------+-----+\n",
      "|              race|Cantidad|Share|\n",
      "+------------------+--------+-----+\n",
      "|             White|   41762| 85.5|\n",
      "|             Black|    4685| 9.59|\n",
      "|Asian-Pac-Islander|    1519| 3.11|\n",
      "|Amer-Indian-Eskimo|     470| 0.96|\n",
      "|             Other|     406| 0.83|\n",
      "|              race|       1|  0.0|\n",
      "+------------------+--------+-----+\n",
      "\n",
      "+------+--------+-----+\n",
      "|   sex|Cantidad|Share|\n",
      "+------+--------+-----+\n",
      "|  Male|   32650|66.85|\n",
      "|Female|   16192|33.15|\n",
      "|   sex|       1|  0.0|\n",
      "+------+--------+-----+\n",
      "\n",
      "+------------------+--------+-----+\n",
      "|    native_country|Cantidad|Share|\n",
      "+------------------+--------+-----+\n",
      "|     United-States|   43832|89.74|\n",
      "|            Mexico|     951| 1.95|\n",
      "|       Philippines|     295|  0.6|\n",
      "|           Germany|     206| 0.42|\n",
      "|       Puerto-Rico|     184| 0.38|\n",
      "|            Canada|     182| 0.37|\n",
      "|       El-Salvador|     155| 0.32|\n",
      "|             India|     151| 0.31|\n",
      "|              Cuba|     138| 0.28|\n",
      "|           England|     127| 0.26|\n",
      "|             China|     122| 0.25|\n",
      "|             South|     115| 0.24|\n",
      "|           Jamaica|     106| 0.22|\n",
      "|             Italy|     105| 0.21|\n",
      "|Dominican-Republic|     103| 0.21|\n",
      "|             Japan|      92| 0.19|\n",
      "|         Guatemala|      88| 0.18|\n",
      "|            Poland|      87| 0.18|\n",
      "|           Vietnam|      86| 0.18|\n",
      "|          Columbia|      85| 0.17|\n",
      "+------------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+--------+-----+\n",
      "|class|Cantidad|Share|\n",
      "+-----+--------+-----+\n",
      "|<=50K|   37155|76.07|\n",
      "| >50K|   11687|23.93|\n",
      "|class|       1|  0.0|\n",
      "+-----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in categoricas:\n",
    "    df_spark.groupBy(col)\\\n",
    "    .agg(F.count(col)\\\n",
    "    .alias('Cantidad'),F.round((F.count(col)/df_spark.count())*100,2)\\\n",
    "    .alias('Share'))\\\n",
    "    .orderBy(F.col('Cantidad').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## realizar mínimo 5 conclusiones de las medias de tendencia central y de dispersion calculadas y previamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La edad tiene un valor muy bajo, estamos tratando con un set de adultos, se tiene la hipotesis que puede ser una llave privada o una variable categorica de la cual no tenemos un contexto adecuado.\n",
    "- El 69,5% de los adultos del dataset son de workclass `Private`, seguidos por los `Self-emp-not-inc` con un 7,9%.\n",
    "- dsa\n",
    "- dsad\n",
    "- sadsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Private             33906\n",
       "Self-emp-not-inc     3862\n",
       "Local-gov            3136\n",
       "State-gov            1981\n",
       "Self-emp-inc         1695\n",
       "Federal-gov          1432\n",
       "Without-pay            21\n",
       "Never-worked           10\n",
       "Name: workclass, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult.workclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
