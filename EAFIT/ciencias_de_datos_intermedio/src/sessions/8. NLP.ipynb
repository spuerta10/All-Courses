{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cd7cbf",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "\n",
    "<img src=\"nlp_b.jpg\" height=\"600\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7280790c",
   "metadata": {},
   "source": [
    "El procesamiento del lenguaje natural es la disciplina que existe en la intersección de la lingüística y la ciencia de datos, que también se correlaciona con una serie de otros campos.\n",
    "\n",
    "El procesamiento del lenguaje natural se puede definir como un subcampo dela inteligencia artificial que aprovecha las herramientas, técnicas y algoritmos de IA y ML para comprender los datos no estructurados del lenguaje natural y derivar significado de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d6c4f",
   "metadata": {},
   "source": [
    "## Steps NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e4582",
   "metadata": {},
   "source": [
    "### Segmentation\n",
    "\n",
    "El primer paso en el procesamiento del lenguaje natural es dividir las oraciones en objetos separados. Esta etapa es bastante fácil. Un algoritmo inteligente de IA filtra los conjuntos de datos y define los signos de puntuación. Cada vez que nota un punto, considera la oración terminada y la separa de todo el texto. Esta etapa es importante ya que permite que el modelo de PNL derive el significado de la oración y luego pase al análisis de todo el párrafo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84a053",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Al tokenizar, puede dividir convenientemente el texto por palabra o por oración. Esto le permitirá trabajar con fragmentos de texto más pequeños que siguen siendo relativamente coherentes y significativos, incluso fuera del contexto del resto del texto. Es su primer paso para convertir datos no estructurados en datos estructurados, que son más fáciles de analizar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e854cad7",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "es una tarea de procesamiento de texto en la que se reducen las palabras a suraíz, que es la parte central de una \n",
    "palabra. Por ejemplo, las palabras \"ayuda\" y \"ayudante\" comparten la raíz \"ayuda\". \n",
    "Stemming le permite concentrarse en el significado básico de una palabra en lugar \n",
    "de todos los detalles de cómo se está utilizando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4e2dbd",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "La mayoría de los textos y oraciones contienen palabras raíz, así como palabras con diferentes formas gramaticales. El procesamiento del lenguaje natural se utiliza aquí para ayudar a la máquina a identificar el significado y categorizar estas palabras. Por ejemplo, es posible que vea las palabras \"población\" y \"poblada\" en el mismo texto. Aunque pertenecen a diferentes partes del habla, el significado de estas palabras es bastante similar.\n",
    "\n",
    "Los modelos de PNL se aplican aquí para averiguar el \"lema\" de cada token, que es la forma básica de cada palabra. Este paso ayuda a un sistema de IA a comprender el concepto central del texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8efe6c0",
   "metadata": {},
   "source": [
    "### Stop Words\n",
    "\n",
    "El siguiente paso esencial en el procesamiento del lenguaje natural es identificar las palabras vacías y filtrarlas antes de decodificar el significado central del texto. Cada idioma tiene una serie de enlazadores y palabras de \"relleno\" que no agregan ningún significado adicional al texto, pero aparecen con frecuencia en el habla o en un texto escrito casualmente.\n",
    "\n",
    "Tales objetos pueden producir un tipo de ruido que impedirá que un sistema NLP obtenga información de los datos. Por lo tanto, las canalizaciones de NLP generalmente marcan estos tokens como \"palabras de parada\" y los omiten al analizar su texto o cualquier otro dato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e110e",
   "metadata": {},
   "source": [
    "## NLTK (Natural Language Toolkit)\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"NLP.jpg\" height=\"700\" width=\"700\">\n",
    "<br>\n",
    "<br>\n",
    "Este Toolkit es ampliamente utilizado para el NLP con Python, es una de las librerías mas comunes pára este tipo de aplicaciones, se puede aplicar para procesamiento de texto para clasificación, tokenización, derivación, etiquetado y análisis de sentimientos.\n",
    "\n",
    "- Documentación: https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d9bf2b",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65c7d748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:33:24.919300Z",
     "start_time": "2022-11-02T11:33:24.901358Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install nltk\n",
    "from nltk import download\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1cd3ae",
   "metadata": {},
   "source": [
    "### Download corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9bf6d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:18:56.288008Z",
     "start_time": "2022-11-02T11:18:32.698115Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download(\"stopwords\")\n",
    "download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c3be3",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd278732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T13:15:21.521589Z",
     "start_time": "2022-11-01T13:15:21.510521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Juan aprendió rápidamente porque su primer entrenamiento fue en cómo aprender.\\nY la primera lección de todas fue la confianza básica que podía aprender.\\nEs impactante encontrar cuántas personas no creen que pueden aprender,\\ny cuantos más creen que aprender es difícil'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_string = \"\"\"Juan aprendió rápidamente porque su primer entrenamiento fue en cómo aprender.\n",
    "Y la primera lección de todas fue la confianza básica que podía aprender.\n",
    "Es impactante encontrar cuántas personas no creen que pueden aprender,\n",
    "y cuantos más creen que aprender es difícil\"\"\"\n",
    "\n",
    "example_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aed6c0f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T13:17:39.287936Z",
     "start_time": "2022-11-01T13:17:39.249756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Juan aprendió rápidamente porque su primer entrenamiento fue en cómo aprender.',\n",
       " 'Y la primera lección de todas fue la confianza básica que podía aprender.',\n",
       " 'Es impactante encontrar cuántas personas no creen que pueden aprender,\\ny cuantos más creen que aprender es difícil']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(example_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8c9f19f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T13:18:37.147493Z",
     "start_time": "2022-11-01T13:18:37.131585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Juan', 'aprendió', 'rápidamente', 'porque', 'su', 'primer', 'entrenamiento', 'fue', 'en', 'cómo', 'aprender', '.', 'Y', 'la', 'primera', 'lección', 'de', 'todas', 'fue', 'la', 'confianza', 'básica', 'que', 'podía', 'aprender', '.', 'Es', 'impactante', 'encontrar', 'cuántas', 'personas', 'no', 'creen', 'que', 'pueden', 'aprender', ',', 'y', 'cuantos', 'más', 'creen', 'que', 'aprender', 'es', 'difícil']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(example_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcec01a9",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41735423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:33:23.599127Z",
     "start_time": "2022-11-21T23:33:23.591171Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_words(string, word_token = True, leng = \"spanish\"):\n",
    "    \n",
    "    stop_words = stopwords.words(leng)\n",
    "    stop_words.extend([\"-\", \".\", \",\", \";\", \"(\", \")\"])\n",
    "    \n",
    "    if word_token == True:\n",
    "        words = word_tokenize(string)\n",
    "    else:\n",
    "        words = sent_tokenize(string)\n",
    "        \n",
    "    return [word.lower() for word in words if not word in stop_words and len(word) >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4008b45e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:33:24.745941Z",
     "start_time": "2022-11-21T23:33:24.732975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['juan',\n",
       " 'aprendió',\n",
       " 'rápidamente',\n",
       " 'primer',\n",
       " 'entrenamiento',\n",
       " 'cómo',\n",
       " 'aprender',\n",
       " 'primera',\n",
       " 'lección',\n",
       " 'todas',\n",
       " 'confianza',\n",
       " 'básica',\n",
       " 'podía',\n",
       " 'aprender',\n",
       " 'impactante',\n",
       " 'encontrar',\n",
       " 'cuántas',\n",
       " 'personas',\n",
       " 'creen',\n",
       " 'pueden',\n",
       " 'aprender',\n",
       " 'cuantos',\n",
       " 'creen',\n",
       " 'aprender',\n",
       " 'difícil']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_string = \"\"\"Juan aprendió rápidamente porque su primer entrenamiento fue en cómo aprender.\n",
    "Y la primera lección de todas fue la confianza básica que podía aprender.\n",
    "Es impactante encontrar cuántas personas no creen que pueden aprender,\n",
    "y cuantos más creen que aprender es difícil\"\"\"\n",
    "\n",
    "clean_words(example_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f00a4",
   "metadata": {},
   "source": [
    "### Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c54e1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:20:33.943422Z",
     "start_time": "2022-11-02T11:20:33.911413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tripulación',\n",
       " 'uss',\n",
       " 'discovery',\n",
       " 'descubrió',\n",
       " 'descubrimientos',\n",
       " 'descubrir',\n",
       " 'hacen',\n",
       " 'exploradores']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = \"\"\"La tripulación del USS Discovery descubrió muchos descubrimientos.\n",
    "Descubrir es lo que hacen los exploradores.\"\"\"\n",
    "\n",
    "words = clean_words(string = words, word_token = True)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8318b81b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:23:08.472381Z",
     "start_time": "2022-11-02T11:23:08.449184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tripulación',\n",
       " 'uss',\n",
       " 'discoveri',\n",
       " 'descubrió',\n",
       " 'descubrimiento',\n",
       " 'descubrir',\n",
       " 'hacen',\n",
       " 'explorador']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stem_words = [stemmer.stem(word) for word in words]\n",
    "stem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "219a1482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:24:22.716783Z",
     "start_time": "2022-11-02T11:24:22.701380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tripul',\n",
       " 'uss',\n",
       " 'discovery',\n",
       " 'descubr',\n",
       " 'descubr',\n",
       " 'descubr',\n",
       " 'hac',\n",
       " 'explor']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer_sp = SnowballStemmer(\"spanish\")\n",
    "stem_words = [stemmer_sp.stem(word) for word in words]\n",
    "stem_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec22a5b",
   "metadata": {},
   "source": [
    "### Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ea2e03e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:27:00.411945Z",
     "start_time": "2022-11-02T11:27:00.398610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tripulación',\n",
       " 'uss',\n",
       " 'discovery',\n",
       " 'descubrió',\n",
       " 'descubrimientos',\n",
       " 'descubrir',\n",
       " 'hacen',\n",
       " 'exploradores']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = \"\"\"La tripulación del USS Discovery descubrió muchos descubrimientos.\n",
    "Descubrir es lo que hacen los exploradores.\"\"\"\n",
    "words = clean_words(string = words, word_token = True)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63563a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(item):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    return lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f69afdcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:27:39.735073Z",
     "start_time": "2022-11-02T11:27:38.366204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tripulación',\n",
       " 'us',\n",
       " 'discovery',\n",
       " 'descubrió',\n",
       " 'descubrimientos',\n",
       " 'descubrir',\n",
       " 'hacen',\n",
       " 'exploradores']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemma_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "lemma_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d6dd5",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "El análisis de sentimientos es ampliamente utilizado dentro del NLP para detectar la intención de un texto con base a lso sentimientos que en general se reducen a estos tres: \n",
    "\n",
    "- Intención negativa\n",
    "- Intención Positiva\n",
    "- Intención Neutra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd0fec",
   "metadata": {},
   "source": [
    "### NLTK With VADER\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"nlp_s.jpg\" height=\"700\" width=\"700\">\n",
    "<br>\n",
    "<br>\n",
    "NLTK dispone de un corpus llamado Vader, el cual permite analizar sentimientos de oraciones y frases cortas, \n",
    "especialmente reviews y comentarios de redes sociales, Vader es un modelo preentrenadoq ue se puede utilizar para lograr un acercamiento a la hora de analizar sentimientos de un texto.\n",
    "\n",
    "- **Nota:** Vader no es un modelo realmente bueno si lo que se desea es analizar sentimientos de parrafos de texto u oraciones demasiado largas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6082e32a",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a180ceac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:28:24.951433Z",
     "start_time": "2022-11-21T23:28:24.931237Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from nltk import download\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b790efb",
   "metadata": {},
   "source": [
    "#### Download Corpus\n",
    "\n",
    "NLTK dispone de diferentes coprus que han sido recopílados y que son bastante útiles para diferentes anlisis:\n",
    "\n",
    "- **names:** Una lista de nombres comunes en inglés compilada por Mark Kantrowitz\n",
    "- **stopwords:** Una lista de palabras realmente comunes, como artículos, pronombres, preposiciones y conjunciones\n",
    "- **state_union:** Una muestra de discursos transcritos sobre el Estado de la Unión por diferentes presidentes de los Estados Unidos, compilados por Kathleen Ahrens\n",
    "- **twitter_samples:** Una lista de frases de redes sociales publicadas en Twitter\n",
    "- **movie_reviews:** Dos mil reseñas de películas categorizadas por Bo Pang y Lillian Lee\n",
    "- **averaged_perceptron_tagger:** Un modelo de datos que NLTK utiliza para categorizar las palabras en su parte del habla\n",
    "- **vader_lexicon:** Una lista puntuada de palabras y jerga a la que NLTK hace referencia al realizar análisis de sentimiento, creada por C.J. Hutto y Eric Gilbert\n",
    "- **punkt:** Un modelo de datos creado por Jan Strunk que NLTK utiliza para dividir textos completos en listas de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25dec4da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:28:29.946002Z",
     "start_time": "2022-11-21T23:28:29.391184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\usuario1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\usuario1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\usuario1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download([\"names\", \"stopwords\", \"vader_lexicon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14046e46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:28:33.810199Z",
     "start_time": "2022-11-21T23:28:33.774424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'compound': 0.6239}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "print(sia.polarity_scores(\"Wow, Que buen curso!\"))\n",
    "print(sia.polarity_scores(\"34tqw342345123!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c61bb43c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:28:39.585573Z",
     "start_time": "2022-11-21T23:28:35.247304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon = pd.read_csv(\"./datasets/Reviews.csv\")\n",
    "print(df_amazon.shape)\n",
    "df_amazon.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8855607c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:47:51.937218Z",
     "start_time": "2022-11-02T11:47:51.925222Z"
    }
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "for i, row in tqdm(df_amazon.iterrows(), total = len(df_amazon)):\n",
    "    result[row[\"Id\"]] = sia.polarity_scores(row[\"Text\"])\n",
    "    \n",
    "vader_result = pd.DataFrame(result).T\n",
    "vader_result = vader_result.reset_index().rename(columns = {\"index\": \"Id\"})\n",
    "df_result_end = pd.concat([df_amazon, vader_result], axis = 1).dropna()\n",
    "df_result_end.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f08254fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:49:24.507398Z",
     "start_time": "2022-11-02T11:49:22.797026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.9441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.9468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    neg    neu    pos  compound\n",
       "0   1  0.000  0.695  0.305    0.9441\n",
       "1   2  0.138  0.862  0.000   -0.5664\n",
       "2   3  0.091  0.754  0.155    0.8265\n",
       "3   4  0.000  1.000  0.000    0.0000\n",
       "4   5  0.000  0.552  0.448    0.9468"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_result = pd.DataFrame(result).T\n",
    "vader_result = vader_result.reset_index().rename(columns = {\"index\": \"Id\"})\n",
    "vader_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3458af44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:50:40.984162Z",
     "start_time": "2022-11-02T11:50:40.972193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63140, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d4eb857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:51:15.891756Z",
     "start_time": "2022-11-02T11:51:15.328741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63135, 15)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_end = pd.concat([df_amazon, vader_result], axis = 1).dropna()\n",
    "df_result_end.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4666c799",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:51:28.403900Z",
     "start_time": "2022-11-02T11:51:28.365020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Id</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.9441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.9468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "    Id    neg    neu    pos  compound  \n",
       "0  1.0  0.000  0.695  0.305    0.9441  \n",
       "1  2.0  0.138  0.862  0.000   -0.5664  \n",
       "2  3.0  0.091  0.754  0.155    0.8265  \n",
       "3  4.0  0.000  1.000  0.000    0.0000  \n",
       "4  5.0  0.000  0.552  0.448    0.9468  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_end.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a868eba6",
   "metadata": {},
   "source": [
    "## Ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93700e81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:56:53.491365Z",
     "start_time": "2022-11-21T23:56:49.103432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon = pd.read_csv(\"./datasets/Reviews.csv\")\n",
    "print(df_amazon.shape)\n",
    "df_amazon.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1d72a6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:56:53.707101Z",
     "start_time": "2022-11-21T23:56:53.694680Z"
    }
   },
   "outputs": [],
   "source": [
    "def stop_words_clean(string, word_token = True, leng = \"spanish\"):\n",
    "    \n",
    "    stop_words = stopwords.words(leng)\n",
    "    stop_words.extend([\"-\", \".\", \",\", \";\", \"(\", \")\"])\n",
    "    \n",
    "    if word_token == True:\n",
    "        words = word_tokenize(string)\n",
    "    else:\n",
    "        words = sent_tokenize(string)\n",
    "        \n",
    "    result = [word.lower() for word in words if not word in stop_words and len(word) >= 3] \n",
    "    \n",
    "    result_end = \" \".join(result)\n",
    "    \n",
    "    return result_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2a4d1ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:53:03.196296Z",
     "start_time": "2022-11-21T23:53:03.175353Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\usuario1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\usuario1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\usuario1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download([\"names\", \"stopwords\", \"vader_lexicon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce8ddbf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:56:53.862223Z",
     "start_time": "2022-11-21T23:56:53.847544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon_new = df_amazon.iloc[0:10000, :]\n",
    "df_amazon_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ffd4a5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:57:10.622510Z",
     "start_time": "2022-11-21T23:56:56.759441Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario1\\AppData\\Local\\Temp\\ipykernel_13576\\2207331341.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_amazon_new[\"Text\"] = df_amazon_new[\"Text\"].apply(lambda x: stop_words_clean(string = x,\n"
     ]
    }
   ],
   "source": [
    "df_amazon_new[\"Text\"] = df_amazon_new[\"Text\"].apply(lambda x: stop_words_clean(string = x, \n",
    "                                                                               word_token = True, \n",
    "                                                                               leng = \"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad8224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37253bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0049dd39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c931cde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:57:10.791433Z",
     "start_time": "2022-11-21T23:57:10.764714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>have bought several the vitality canned dog fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>product arrived labeled jumbo salted peanuts ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>this confection that been around few centuries...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>you are looking for the secret ingredient robi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>great taffy great price there was wide assortm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>A3A63RACXR1XIL</td>\n",
       "      <td>A. Boodhoo \"deaddodo\"</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1204502400</td>\n",
       "      <td>constipation</td>\n",
       "      <td>switched from the advance similac the organic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>A5VVRGL8JA7R</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1306368000</td>\n",
       "      <td>Constipation Not A Problem if...</td>\n",
       "      <td>like the bad reviews say the organic formula c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>A2TGDTJ8YCU6PD</td>\n",
       "      <td>geena77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1347494400</td>\n",
       "      <td>Love this formula!</td>\n",
       "      <td>wanted solely breastfeed but was unable keep a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>AUV4GIZZE693O</td>\n",
       "      <td>Susan Coe \"sueysis\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1203638400</td>\n",
       "      <td>very convenient</td>\n",
       "      <td>love the fact that can get this delieved house...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>A82WIMR4RSVLI</td>\n",
       "      <td>Emrose mom</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1337472000</td>\n",
       "      <td>The best weve tried so far</td>\n",
       "      <td>have week old ... had gas and constipation pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id   ProductId          UserId                      ProfileName  \\\n",
       "0         1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1         2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2         3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3         4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4         5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...     ...         ...             ...                              ...   \n",
       "9995   9996  B000P41A28  A3A63RACXR1XIL            A. Boodhoo \"deaddodo\"   \n",
       "9996   9997  B000P41A28    A5VVRGL8JA7R                             Adam   \n",
       "9997   9998  B000P41A28  A2TGDTJ8YCU6PD                          geena77   \n",
       "9998   9999  B000P41A28   AUV4GIZZE693O              Susan Coe \"sueysis\"   \n",
       "9999  10000  B000P41A28   A82WIMR4RSVLI                       Emrose mom   \n",
       "\n",
       "      HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                        1                       1      5  1303862400   \n",
       "1                        0                       0      1  1346976000   \n",
       "2                        1                       1      4  1219017600   \n",
       "3                        3                       3      2  1307923200   \n",
       "4                        0                       0      5  1350777600   \n",
       "...                    ...                     ...    ...         ...   \n",
       "9995                    10                      15      1  1204502400   \n",
       "9996                     2                       3      5  1306368000   \n",
       "9997                     0                       0      5  1347494400   \n",
       "9998                     1                       2      5  1203638400   \n",
       "9999                     0                       1      4  1337472000   \n",
       "\n",
       "                               Summary  \\\n",
       "0                Good Quality Dog Food   \n",
       "1                    Not as Advertised   \n",
       "2                \"Delight\" says it all   \n",
       "3                       Cough Medicine   \n",
       "4                          Great taffy   \n",
       "...                                ...   \n",
       "9995                      constipation   \n",
       "9996  Constipation Not A Problem if...   \n",
       "9997                Love this formula!   \n",
       "9998                   very convenient   \n",
       "9999        The best weve tried so far   \n",
       "\n",
       "                                                   Text  \n",
       "0     have bought several the vitality canned dog fo...  \n",
       "1     product arrived labeled jumbo salted peanuts ....  \n",
       "2     this confection that been around few centuries...  \n",
       "3     you are looking for the secret ingredient robi...  \n",
       "4     great taffy great price there was wide assortm...  \n",
       "...                                                 ...  \n",
       "9995  switched from the advance similac the organic ...  \n",
       "9996  like the bad reviews say the organic formula c...  \n",
       "9997  wanted solely breastfeed but was unable keep a...  \n",
       "9998  love the fact that can get this delieved house...  \n",
       "9999  have week old ... had gas and constipation pro...  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f536869d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:55:16.666742Z",
     "start_time": "2022-11-21T23:54:58.135618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38395251f2c44ca1a5ef52eb76f82aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 15)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = {}\n",
    "for i, row in tqdm(df_amazon_new.iterrows(), total = len(df_amazon_new)):\n",
    "    result[row[\"Id\"]] = sia.polarity_scores(row[\"Text\"])\n",
    "    \n",
    "vader_result = pd.DataFrame(result).T\n",
    "vader_result = vader_result.reset_index().rename(columns = {\"index\": \"Id\"})\n",
    "df_result_end = pd.concat([df_amazon_new, vader_result], axis = 1).dropna()\n",
    "df_result_end.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4610f4f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:58:05.389891Z",
     "start_time": "2022-11-21T23:58:05.346961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Id</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.9441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.9468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>A3A63RACXR1XIL</td>\n",
       "      <td>A. Boodhoo \"deaddodo\"</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1204502400</td>\n",
       "      <td>constipation</td>\n",
       "      <td>we switched from the advance similac to the or...</td>\n",
       "      <td>9996</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>A5VVRGL8JA7R</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1306368000</td>\n",
       "      <td>Constipation Not A Problem if...</td>\n",
       "      <td>Like the bad reviews say, the organic formula ...</td>\n",
       "      <td>9997</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.6808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>A2TGDTJ8YCU6PD</td>\n",
       "      <td>geena77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1347494400</td>\n",
       "      <td>Love this formula!</td>\n",
       "      <td>I wanted to solely breastfeed but was unable t...</td>\n",
       "      <td>9998</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.9305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>AUV4GIZZE693O</td>\n",
       "      <td>Susan Coe \"sueysis\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1203638400</td>\n",
       "      <td>very convenient</td>\n",
       "      <td>i love the fact that i can get this delieved t...</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>A82WIMR4RSVLI</td>\n",
       "      <td>Emrose mom</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1337472000</td>\n",
       "      <td>The best weve tried so far</td>\n",
       "      <td>We have a 7 week old... He had gas and constip...</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.9850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id   ProductId          UserId                      ProfileName  \\\n",
       "0         1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1         2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2         3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3         4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4         5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...     ...         ...             ...                              ...   \n",
       "9995   9996  B000P41A28  A3A63RACXR1XIL            A. Boodhoo \"deaddodo\"   \n",
       "9996   9997  B000P41A28    A5VVRGL8JA7R                             Adam   \n",
       "9997   9998  B000P41A28  A2TGDTJ8YCU6PD                          geena77   \n",
       "9998   9999  B000P41A28   AUV4GIZZE693O              Susan Coe \"sueysis\"   \n",
       "9999  10000  B000P41A28   A82WIMR4RSVLI                       Emrose mom   \n",
       "\n",
       "      HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                        1                       1      5  1303862400   \n",
       "1                        0                       0      1  1346976000   \n",
       "2                        1                       1      4  1219017600   \n",
       "3                        3                       3      2  1307923200   \n",
       "4                        0                       0      5  1350777600   \n",
       "...                    ...                     ...    ...         ...   \n",
       "9995                    10                      15      1  1204502400   \n",
       "9996                     2                       3      5  1306368000   \n",
       "9997                     0                       0      5  1347494400   \n",
       "9998                     1                       2      5  1203638400   \n",
       "9999                     0                       1      4  1337472000   \n",
       "\n",
       "                               Summary  \\\n",
       "0                Good Quality Dog Food   \n",
       "1                    Not as Advertised   \n",
       "2                \"Delight\" says it all   \n",
       "3                       Cough Medicine   \n",
       "4                          Great taffy   \n",
       "...                                ...   \n",
       "9995                      constipation   \n",
       "9996  Constipation Not A Problem if...   \n",
       "9997                Love this formula!   \n",
       "9998                   very convenient   \n",
       "9999        The best weve tried so far   \n",
       "\n",
       "                                                   Text     Id    neg    neu  \\\n",
       "0     I have bought several of the Vitality canned d...      1  0.000  0.695   \n",
       "1     Product arrived labeled as Jumbo Salted Peanut...      2  0.138  0.862   \n",
       "2     This is a confection that has been around a fe...      3  0.091  0.754   \n",
       "3     If you are looking for the secret ingredient i...      4  0.000  1.000   \n",
       "4     Great taffy at a great price.  There was a wid...      5  0.000  0.552   \n",
       "...                                                 ...    ...    ...    ...   \n",
       "9995  we switched from the advance similac to the or...   9996  0.089  0.852   \n",
       "9996  Like the bad reviews say, the organic formula ...   9997  0.091  0.747   \n",
       "9997  I wanted to solely breastfeed but was unable t...   9998  0.063  0.811   \n",
       "9998  i love the fact that i can get this delieved t...   9999  0.149  0.697   \n",
       "9999  We have a 7 week old... He had gas and constip...  10000  0.026  0.811   \n",
       "\n",
       "        pos  compound  \n",
       "0     0.305    0.9441  \n",
       "1     0.000   -0.5664  \n",
       "2     0.155    0.8265  \n",
       "3     0.000    0.0000  \n",
       "4     0.448    0.9468  \n",
       "...     ...       ...  \n",
       "9995  0.059   -0.5267  \n",
       "9996  0.162    0.6808  \n",
       "9997  0.126    0.9305  \n",
       "9998  0.154    0.2809  \n",
       "9999  0.164    0.9850  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
